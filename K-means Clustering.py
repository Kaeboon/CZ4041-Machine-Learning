# -*- coding: utf-8 -*-
"""K-Means Clustering
By: Micole

Automatically generated by Colaboratory.

#Load the Kaggle Dataset
"""

!pip install kaggle
import os
os.environ['KAGGLE_USERNAME'] = 'hokaeboon' # username
os.environ['KAGGLE_KEY'] = '1e019fc3adba59103ed755ece52c24c7' # key
from google.colab import drive
drive.mount('/content/drive')
!kaggle competitions download -c recognizing-faces-in-the-wild
!unzip -q recognizing-faces-in-the-wild.zip

import os
os.environ['KAGGLE_USERNAME'] = 'hokaeboon' # username
os.environ['KAGGLE_KEY'] = '1e019fc3adba59103ed755ece52c24c7' # key

from google.colab import drive
drive.mount('/content/drive')

!kaggle competitions download -c recognizing-faces-in-the-wild

!unzip -q recognizing-faces-in-the-wild.zip

"""#Exploratory Data Analysis"""

# Import relevant libraries
from glob import glob
from collections import defaultdict
from random import choice, sample

import os
import pandas as pd
import numpy as np
import zipfile
from pathlib import Path
import plotly.graph_objs as go
import plotly.offline as py
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.decomposition import PCA
from keras.preprocessing import image
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.models import load_model

train_relationships = pd.read_csv('train_relationships.csv')
print(train_relationships.head())
print(train_relationships.shape)
# There are 3598 relationships in total.

path_to_zip_file = "train.zip"
directory_to_extract_to = "../output/train"
train_images =  Path('../output/train/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser("../output/train")) for f in fn]
train_images_df = pd.DataFrame({
    'files': files,
    'familyId': [file.split('/')[3] for file in files],
    'kinId': [file.split('/')[4] for file in files],
    'uniqueId': [file.split('/')[3] + '/' + file.split('/')[4] for file in files]
})
train_images_df.head(10)

print("Total number of members in the dataset: {0}".format(train_images_df["uniqueId"].nunique()))
print("Total number of families in the dataset: {0}".format(train_images_df["familyId"].nunique()))

family_with_most_pic = train_images_df["familyId"].value_counts()
kin_with_most_pic = train_images_df["uniqueId"].value_counts()

print("Family with maximum number of images: {0}, Image Count: {1}".format(family_with_most_pic.index[0], family_with_most_pic[0]))
print("Member with maximum number of images: {0}, Image Count: {1}".format(kin_with_most_pic.index[0], kin_with_most_pic[0]))

"""#Data Preprocessing"""

import struct
import imghdr
image_size = []
def get_image_size(data):
  for fname in data:
      '''Determine the image type of fhandle and return its size.
      from draco'''
      with open(fname, 'rb') as fhandle:
          head = fhandle.read(24)
          if len(head) != 24:
              return
          if imghdr.what(fname) == 'png':
              check = struct.unpack('>i', head[4:8])[0]
              if check != 0x0d0a1a0a:
                  return
              width, height = struct.unpack('>ii', head[16:24])
          elif imghdr.what(fname) == 'gif':
              width, height = struct.unpack('<HH', head[6:10])
          elif imghdr.what(fname) == 'jpeg':
              try:
                  fhandle.seek(0) # Read 0xff next
                  size = 2
                  ftype = 0
                  while not 0xc0 <= ftype <= 0xcf:
                      fhandle.seek(size, 1)
                      byte = fhandle.read(1)
                      while ord(byte) == 0xff:
                          byte = fhandle.read(1)
                      ftype = ord(byte)
                      size = struct.unpack('>H', fhandle.read(2))[0] - 2
                  # We are at a SOFn block
                  fhandle.seek(1, 1)  # Skip `precision' byte.
                  height, width = struct.unpack('>HH', fhandle.read(4))
              except Exception: #IGNORE:W0703
                  return
          else:
              return
          image_size.append((width, height))

get_image_size(train_images_df.files)

pd.Series(image_size).unique()

print(image_size)

# Split into training and validation sets
train_file_path = "../content/train_relationships.csv"
train_folders_path = "../output/train/"
val_famillies = "F09"

all_images = glob(train_folders_path + "*/*/*.jpg")
train_images = [x for x in all_images if val_famillies not in x]
val_images = [x for x in all_images if val_famillies in x]

print(all_images)
new_list = []
for i in all_images:
  count=0
  new_word = ""
  for alphabet in i:
    if(alphabet == '/'):
      count+=1
    if(count==5):
      new_list.append(new_word)
      break
    new_word+=alphabet

print(new_list)
print(len(new_list))

print((all_images))

print(len(all_images))
print(len(train_images))
print(len(val_images))

train_person_to_images_map = defaultdict(list)
ppl = [x.split("/")[-3] + "/" + x.split("/")[-2] for x in all_images]

for x in train_images:
    train_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

val_person_to_images_map = defaultdict(list)

for x in val_images:
    val_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

relationships = pd.read_csv(train_file_path)
relationships = list(zip(relationships.p1.values, relationships.p2.values))
# not_in = [x for x in relationships if x[0] not in ppl and x[1] not in ppl]
relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]
# not_in
# We realise that there are some individuals that are not found in train.zip but are found in the train_relationships.csv table

train = [x for x in relationships if val_famillies not in x[0]]
val = [x for x in relationships if val_famillies in x[0]]

print(len(train))
print(len(val))

print(train)

print(train_person_to_images_map)

"""The following variables were created above


*   train: consists of relationships for training
*   train_person_to_images_map: consists of the image paths for training
*   val: consists of relationships for validation
*   val_person_to_images_map: consists of the image paths for validation

# Data Preprocessing 2
"""

import cv2
# create a function to create,load,resize, and re-color the data
def create_data(path):
  list_new_array=[]
  for img in os.listdir(path):
        try:
            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)
            size=100
            new_array=cv2.resize(img_array,(size,size))
            list_new_array.append(new_array)
        except Exception as e:
            pass

  return list_new_array

#combine images
def combine_images(path):
  new_img = create_data(path)
  avg_image = new_img[0]
  for i in range(len(new_img)):
    if i==0:
      pass
    else:
      a = 1.0/(i+1)
      b = 1.0 - a
      avg_image = cv2.addWeighted(new_img[i], a, avg_image, b, 0.0)
    #plt.figure
    #plt.imshow(avg_image)
  return(avg_image)

# convert dimension of one image
def get_1D_from_input(path):

  a = combine_images(path).reshape((100*100))
  return a

def read_img(path):
  return get_1D_from_input(path)

def person_to_images_map(keyy):
  #print(keyy)
  return ("../output/train/"+keyy)

print(read_img(person_to_images_map("F0703/MID10"))) #testing

def gen(list_tuples, batch_size=300):
    ppl = list(train_person_to_images_map.keys())
    X1 = []
    X2 = []
    labels = []
    batch_tuples=[]

    for i in range(batch_size//2):
      p0 = choice(list_tuples)
      batch_tuples.append(p0)
      labels.append(1)

    for i in range(batch_size - len(batch_tuples)):
        p1 = choice(ppl)
        p2 = choice(ppl)

        if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:
                batch_tuples.append((p1, p2))
                labels.append(0)
        else:
                batch_tuples.append((p1, p2))
                labels.append(1)
    
    #print(person_to_images_map)
    for x in batch_tuples:
        X1.append(read_img(person_to_images_map(x[0])))
        X2.append(read_img(person_to_images_map(x[1])))

    X1 = np.array(X1)
    X2 = np.array(X2)
    labels = np.array(labels)

    return (X1, X2, labels)

output = gen(train, 100)

"""#Building and Evaluating Models"""

# FINDING A GOOD k USING ELBOW METHOD
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score

X1 = output[0].astype(np.int16)/255.0
X2 = output[1].astype(np.int16)/255.0
labels = output[2]
x_train = X2 - X1
y_train = labels

distortions = []
K = range(10,100)
for k in K:
    kmeanModel = KMeans(n_clusters = k, init='k-means++')
    kmeanModel.fit(x_train)
    distortions.append(kmeanModel.inertia_)

plt.figure(figsize=(16,8))
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()

kmeans = KMeans(n_clusters = 16, init='k-means++')
kmeans.fit(x_train)

def infer_cluster_label(cluster_labels, y_train):
    
    ref_labels = {}
    
    for i in range(len(np.unique(kmeans.labels_))):
        index = np.where(cluster_labels == i,1,0)
        num = np.bincount(y_train[index==1]).argmax()
        
        ref_labels[i] = num
        
    return ref_labels

ref_labels = infer_cluster_label(kmeans.labels_, y_train)
predicted_labels = np.random.rand(len(kmeans.labels_))

# Get the predicted actual labels
for i in range(len(kmeans.labels_)):
    predicted_labels[i] = ref_labels[kmeans.labels_[i]]

print("Predicted Labels: ", end="")
print(predicted_labels[:10].astype('int'))

from sklearn.metrics import accuracy_score

print("Accuracy: ", end="")
print(accuracy_score(predicted_labels,y_train))