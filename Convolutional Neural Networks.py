# -*- coding: utf-8 -*-
"""CNNs Neural Network
By: Charmaine

Automatically generated by Colaboratory.

### Load the Kaggle Dataset
"""

#Import files from kaggle to colab python3
!pip install kaggle

import os
os.environ['KAGGLE_USERNAME'] = 'charmainechng' # username
os.environ['KAGGLE_KEY'] = '5f3d662eeac2c12c194b0196596b8e7b' # key

from google.colab import drive
drive.mount('/content/drive')

!kaggle competitions download -c recognizing-faces-in-the-wild

!unzip -q recognizing-faces-in-the-wild.zip

"""### Exploratory Data Analysis"""

# Import relevant libraries
from glob import glob
from collections import defaultdict
from random import choice, sample

import os
import pandas as pd
import numpy as np
import zipfile
from pathlib import Path
import plotly.graph_objs as go
import plotly.offline as py
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.decomposition import PCA
from keras.preprocessing import image
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.models import load_model

train_relationships = pd.read_csv('train_relationships.csv')
print(train_relationships.head())
print(train_relationships.shape)
# There are 3598 relationships in total.

path_to_zip_file = "train.zip"
directory_to_extract_to = "../output/train"
train_images =  Path('../output/train/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser("../output/train")) for f in fn]
train_images_df = pd.DataFrame({
    'files': files,
    'familyId': [file.split('/')[3] for file in files],
    'kinId': [file.split('/')[4] for file in files],
    'uniqueId': [file.split('/')[3] + '/' + file.split('/')[4] for file in files]
})
train_images_df.head(10)

print("Total number of members in the dataset: {0}".format(train_images_df["uniqueId"].nunique()))
print("Total number of families in the dataset: {0}".format(train_images_df["familyId"].nunique()))

family_with_most_pic = train_images_df["familyId"].value_counts()
kin_with_most_pic = train_images_df["uniqueId"].value_counts()

print("Family with maximum number of images: {0}, Image Count: {1}".format(family_with_most_pic.index[0], family_with_most_pic[0]))
print("Member with maximum number of images: {0}, Image Count: {1}".format(kin_with_most_pic.index[0], kin_with_most_pic[0]))

"""### Data Preprocessing
1. Check if images are of the same size (number of pixels)
2. Split the training images into training and validation sets
3. Apply image augmentation
4. Flatten the images
5. Normalize the images
"""

import struct
import imghdr
image_size = []
def get_image_size(data):
  for fname in data:
      '''Determine the image type of fhandle and return its size.
      from draco'''
      with open(fname, 'rb') as fhandle:
          head = fhandle.read(24)
          if len(head) != 24:
              return
          if imghdr.what(fname) == 'png':
              check = struct.unpack('>i', head[4:8])[0]
              if check != 0x0d0a1a0a:
                  return
              width, height = struct.unpack('>ii', head[16:24])
          elif imghdr.what(fname) == 'gif':
              width, height = struct.unpack('<HH', head[6:10])
          elif imghdr.what(fname) == 'jpeg':
              try:
                  fhandle.seek(0) # Read 0xff next
                  size = 2
                  ftype = 0
                  while not 0xc0 <= ftype <= 0xcf:
                      fhandle.seek(size, 1)
                      byte = fhandle.read(1)
                      while ord(byte) == 0xff:
                          byte = fhandle.read(1)
                      ftype = ord(byte)
                      size = struct.unpack('>H', fhandle.read(2))[0] - 2
                  # We are at a SOFn block
                  fhandle.seek(1, 1)  # Skip `precision' byte.
                  height, width = struct.unpack('>HH', fhandle.read(4))
              except Exception: #IGNORE:W0703
                  return
          else:
              return
          image_size.append((width, height))

get_image_size(train_images_df.files)

pd.Series(image_size).unique()

# Split into training and validation sets
train_file_path = "../content/train_relationships.csv"
train_folders_path = "../output/train/"
val_famillies = "F09"

all_images = glob(train_folders_path + "*/*/*.jpg")
train_images = [x for x in all_images if val_famillies not in x]
val_images = [x for x in all_images if val_famillies in x]

print(len(all_images))
print(len(train_images))
print(len(val_images))

train_person_to_images_map = defaultdict(list)
ppl = [x.split("/")[-3] + "/" + x.split("/")[-2] for x in all_images]

for x in train_images:
    train_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

val_person_to_images_map = defaultdict(list)

for x in val_images:
    val_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

relationships = pd.read_csv(train_file_path)
relationships = list(zip(relationships.p1.values, relationships.p2.values))
# not_in = [x for x in relationships if x[0] not in ppl and x[1] not in ppl]
relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]
# not_in
# We realise that there are some individuals that are not found in train.zip but are found in the train_relationships.csv table

train = [x for x in relationships if val_famillies not in x[0]]
val = [x for x in relationships if val_famillies in x[0]]

print(len(train))
print(len(val))

"""The following variables were created above
- train: consists of relationships for training
- train_person_to_images_map: consists of the image paths for training
- val: consists of relationships for validation
- val_person_to_images_map: consists of the image paths for validation
"""

def read_img(path):
    img = load_img(path)
    img = np.array(img).astype(np.float)
    return preprocess_input(img)   #Preprocess input based on the keras model

def gen(list_tuples, person_to_images_map, batch_size=16):
    ppl = list(person_to_images_map.keys())
    while True:
        batch_tuples = sample(list_tuples, batch_size // 2)
        labels = [1] * len(batch_tuples)

        while len(batch_tuples) < batch_size:
            p1 = choice(ppl)
            p2 = choice(ppl)

            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:
                batch_tuples.append((p1, p2))
                labels.append(0)

        for x in batch_tuples:
            if not len(person_to_images_map[x[0]]):
                print(x[0])

        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]
        X1 = np.array([read_img(x) for x in X1])

        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]
        X2 = np.array([read_img(x) for x in X2])
        labels = np.asarray(labels).astype('float32').reshape((-1,1))

        yield [X1, X2], labels

"""### Building and Evaluating Models

#### Model 1: ResNet50
"""

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.applications.resnet import preprocess_input

def resnet_model():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = ResNet50(weights='imagenet', include_top=False)

    for x in base_model.layers[:-3]:
        x.trainable = True

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.00001))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/resnet50.h5"

resnetmod = resnet_model()
resnetmod_hist = resnetmod.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=20, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = resnetmod.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/resnet50.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(resnetmod_hist.history['loss'], label='loss')
axes[0].plot(resnetmod_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(resnetmod_hist.history['accuracy'], label='acc')
axes[1].plot(resnetmod_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})

load_model_resnet = load_model('/content/drive/MyDrive/CZ4041_Project/resnet50.h5')

"""####Model 2: ResNet50 (Fit Params tweaked)"""

file_path = "/content/drive/MyDrive/CZ4041_Project/resnet50_Version2.h5"

resnetmod2 = resnet_model()
resnetmod2_hist = resnetmod2.fit(gen(train, train_person_to_images_map, batch_size=12),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=1), 
                                           epochs=30, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=30,
                                           validation_steps=30)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = resnetmod.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/resnet50_Version2.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(resnetmod_hist.history['loss'], label='loss')
axes[0].plot(resnetmod_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(resnetmod_hist.history['accuracy'], label='acc')
axes[1].plot(resnetmod_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})

"""#### Model 3: ResNet50 (Please rerun)"""

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.applications.resnet import preprocess_input

def resnet_model2():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = ResNet50(include_top=False, weights='None')

    for x in base_model.layers[:-3]:
        x.trainable = True

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.00001))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/resnet50_Version3.h5"

resnetmod3 = resnet_model2()
resnetmod3_hist = resnetmod3.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=20, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = resnetmod3.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/resnet50_Version3.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(resnetmod3_hist.history['loss'], label='loss')
axes[0].plot(resnetmod3_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(resnetmod3_hist.history['accuracy'], label='acc')
axes[1].plot(resnetmod3_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})



"""#### Model 4: InceptionV3"""

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input

def inceptionv3_model():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = InceptionV3(weights='imagenet', include_top=False)

    for x in base_model.layers[:-3]:
        x.trainable = True

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.00001))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/inceptionv3.h5"

inceptionv3mod = inceptionv3_model()
inceptionv3mod_hist = inceptionv3mod.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=20, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = inceptionv3mod.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/inceptionv3.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(inceptionv3mod_hist.history['loss'], label='loss')
axes[0].plot(inceptionv3mod_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(inceptionv3mod_hist.history['accuracy'], label='acc')
axes[1].plot(inceptionv3mod_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})

"""#### Model 5: VGGFace (ResNet50)"""

!pip install git+https://github.com/rcmalli/keras-vggface.git
!pip install keras_applications --no-deps
filename = "/usr/local/lib/python3.7/dist-packages/keras_vggface/models.py"
text = open(filename).read()
open(filename, "w+").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))
import tensorflow as tf

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

def vggface_model():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = VGGFace(model='resnet50', include_top=False)

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.00001))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/vggface.h5"

vggfacemod = vggface_model()
vggfacemod_hist = vggfacemod.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=20, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = vggfacemod.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/vggface.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(vggfacemod_hist.history['loss'], label='loss')
axes[0].plot(vggfacemod_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(vggfacemod_hist.history['accuracy'], label='acc')
axes[1].plot(vggfacemod_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})

"""#### Model 5: VGGFace (SENet50)"""

!pip install git+https://github.com/rcmalli/keras-vggface.git
!pip install keras_applications --no-deps
filename = "/usr/local/lib/python3.7/dist-packages/keras_vggface/models.py"
text = open(filename).read()
open(filename, "w+").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))
import tensorflow as tf

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

def vggface2_model():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = VGGFace(model='senet50', include_top=False)

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.00001))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/vggface2.h5"

vggfacemod2 = vggface2_model()
vggfacemod2_hist = vggfacemod2.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=20, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = vggfacemod2.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/vggface2.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(vggfacemod2_hist.history['loss'], label='loss')
axes[0].plot(vggfacemod2_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(vggfacemod2_hist.history['accuracy'], label='acc')
axes[1].plot(vggfacemod2_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})

"""#### Model 5: VGGFace (SENet50)"""

!pip install git+https://github.com/rcmalli/keras-vggface.git
!pip install keras_applications --no-deps
filename = "/usr/local/lib/python3.7/dist-packages/keras_vggface/models.py"
text = open(filename).read()
open(filename, "w+").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))
import tensorflow as tf

from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D, Flatten, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

def vggface3_model():
    input_1 = Input(shape=(224, 224, 3))
    input_2 = Input(shape=(224, 224, 3))

    base_model = VGGFace(model='senet50', include_top=False)

    x1 = base_model(input_1)
    x2 = base_model(input_2)

    x1 = Concatenate(axis=-1)([GlobalAvgPool2D()(x1), GlobalAvgPool2D()(x1)])
    x2 = Concatenate(axis=-1)([GlobalAvgPool2D()(x2), GlobalAvgPool2D()(x2)])

    x3 = Subtract()([x1, x2])
    x3 = Multiply()([x3, x3])

    x1_ = Multiply()([x1, x1])
    x2_ = Multiply()([x2, x2])
    x4  = Subtract()([x1_, x2_])    
    x   = Concatenate(axis=-1)([x4, x3])
    x   = Dense(256, activation="relu")(x)
    x   = BatchNormalization()(x)
    x   = Dropout(0.01)(x) 
    x   = Dense(100, activation="relu")(x)    
    out = Dense(1, activation="sigmoid")(x)

    model = Model([input_1, input_2], out)
    model.compile(loss="binary_crossentropy", metrics=['accuracy'], optimizer=Adam(0.01))
    model.summary()

    return model

file_path = "/content/drive/MyDrive/CZ4041_Project/vggface2.h5"

vggfacemod3 = vggface3_model()
vggfacemod3_hist = vggfacemod3.fit(gen(train, train_person_to_images_map, batch_size=16),
                                           use_multiprocessing=True,
                                           validation_data=gen(val, val_person_to_images_map, batch_size=16), 
                                           epochs=40, 
                                           verbose=1,
                                           callbacks=[ModelCheckpoint(file_path,monitor="val_accuracy", verbose=1, save_best_only=True)],
                                           steps_per_epoch=50,
                                           validation_steps=50)

path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1 = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img(test_path + x) for x in X1])

    X2 = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img(test_path + x) for x in X2])

    pred = vggfacemod3.predict([X1, X2]).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/CZ4041_Project/vggface3.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(20, 6))
axes[0].plot(vggfacemod3_hist.history['loss'], label='loss')
axes[0].plot(vggfacemod3_hist.history['val_loss'], label='val_loss')
axes[0].legend(prop={'size':15})
axes[1].plot(vggfacemod3_hist.history['accuracy'], label='acc')
axes[1].plot(vggfacemod3_hist.history['val_accuracy'], label='val_acc')
axes[1].legend(prop={'size':15})