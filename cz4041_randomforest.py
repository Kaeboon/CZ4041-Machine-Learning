# -*- coding: utf-8 -*-
"""CZ4041 RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E7do14a3-VxEs8OpJWaUGwvKLw5N1Uwu

#Load the Kaggle Dataset
"""

!pip install kaggle
import os
os.environ['KAGGLE_USERNAME'] = 'hokaeboon' # username
os.environ['KAGGLE_KEY'] = '1e019fc3adba59103ed755ece52c24c7' # key
from google.colab import drive
drive.mount('/content/drive')
!kaggle competitions download -c recognizing-faces-in-the-wild
!unzip -q recognizing-faces-in-the-wild.zip

import os
os.environ['KAGGLE_USERNAME'] = 'hokaeboon' # username
os.environ['KAGGLE_KEY'] = '1e019fc3adba59103ed755ece52c24c7' # key

from google.colab import drive
drive.mount('/content/drive')

!kaggle competitions download -c recognizing-faces-in-the-wild

!unzip -q recognizing-faces-in-the-wild.zip

"""#Exploratory Data Analysis"""

# Import relevant libraries
from glob import glob
from collections import defaultdict
from random import choice, sample

import os
import pandas as pd
import numpy as np
import zipfile
from pathlib import Path
import plotly.graph_objs as go
import plotly.offline as py
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.decomposition import PCA
from keras.preprocessing import image
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.models import load_model

train_relationships = pd.read_csv('train_relationships.csv')
print(train_relationships.head())
print(train_relationships.shape)
# There are 3598 relationships in total.

path_to_zip_file = "train.zip"
directory_to_extract_to = "../output/train"
train_images =  Path('../output/train/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser("../output/train")) for f in fn]
train_images_df = pd.DataFrame({
    'files': files,
    'familyId': [file.split('/')[3] for file in files],
    'kinId': [file.split('/')[4] for file in files],
    'uniqueId': [file.split('/')[3] + '/' + file.split('/')[4] for file in files]
})
train_images_df.head(10)

print("Total number of members in the dataset: {0}".format(train_images_df["uniqueId"].nunique()))
print("Total number of families in the dataset: {0}".format(train_images_df["familyId"].nunique()))

family_with_most_pic = train_images_df["familyId"].value_counts()
kin_with_most_pic = train_images_df["uniqueId"].value_counts()

print("Family with maximum number of images: {0}, Image Count: {1}".format(family_with_most_pic.index[0], family_with_most_pic[0]))
print("Member with maximum number of images: {0}, Image Count: {1}".format(kin_with_most_pic.index[0], kin_with_most_pic[0]))



"""#Data Preprocessing"""

import struct
import imghdr
image_size = []
def get_image_size(data):
  for fname in data:
      '''Determine the image type of fhandle and return its size.
      from draco'''
      with open(fname, 'rb') as fhandle:
          head = fhandle.read(24)
          if len(head) != 24:
              return
          if imghdr.what(fname) == 'png':
              check = struct.unpack('>i', head[4:8])[0]
              if check != 0x0d0a1a0a:
                  return
              width, height = struct.unpack('>ii', head[16:24])
          elif imghdr.what(fname) == 'gif':
              width, height = struct.unpack('<HH', head[6:10])
          elif imghdr.what(fname) == 'jpeg':
              try:
                  fhandle.seek(0) # Read 0xff next
                  size = 2
                  ftype = 0
                  while not 0xc0 <= ftype <= 0xcf:
                      fhandle.seek(size, 1)
                      byte = fhandle.read(1)
                      while ord(byte) == 0xff:
                          byte = fhandle.read(1)
                      ftype = ord(byte)
                      size = struct.unpack('>H', fhandle.read(2))[0] - 2
                  # We are at a SOFn block
                  fhandle.seek(1, 1)  # Skip `precision' byte.
                  height, width = struct.unpack('>HH', fhandle.read(4))
              except Exception: #IGNORE:W0703
                  return
          else:
              return
          image_size.append((width, height))

get_image_size(train_images_df.files)

pd.Series(image_size).unique()

print(image_size)

# Split into training and validation sets
train_file_path = "../content/train_relationships.csv"
train_folders_path = "../output/train/"
val_famillies = "F09"

all_images = glob(train_folders_path + "*/*/*.jpg")
train_images = [x for x in all_images if val_famillies not in x]
val_images = [x for x in all_images if val_famillies in x]

print(all_images)
new_list = []
for i in all_images:
  count=0
  new_word = ""
  for alphabet in i:
    if(alphabet == '/'):
      count+=1
    if(count==5):
      new_list.append(new_word)
      break
    new_word+=alphabet

print(new_list)
print(len(new_list))

print((all_images))

print(len(all_images))
print(len(train_images))
print(len(val_images))

train_person_to_images_map = defaultdict(list)
ppl = [x.split("/")[-3] + "/" + x.split("/")[-2] for x in all_images]

for x in train_images:
    train_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

val_person_to_images_map = defaultdict(list)

for x in val_images:
    val_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

relationships = pd.read_csv(train_file_path)
relationships = list(zip(relationships.p1.values, relationships.p2.values))
# not_in = [x for x in relationships if x[0] not in ppl and x[1] not in ppl]
relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]
# not_in
# We realise that there are some individuals that are not found in train.zip but are found in the train_relationships.csv table

train = [x for x in relationships if val_famillies not in x[0]]
val = [x for x in relationships if val_famillies in x[0]]

print(len(train))
print(len(val))

print(train)

print(train_person_to_images_map)

"""The following variables were created above


*   train: consists of relationships for training
*   train_person_to_images_map: consists of the image paths for training
*   val: consists of relationships for validation
*   val_person_to_images_map: consists of the image paths for validation

# Data Preprocessing 2
"""

# perform pca on image, not used, ignore
def pca_on_data(path):
  print("pca_on_data")
  print(path)

  num_of_image = len(os.listdir(path))
  img1=np.array(create_data(path))
  img1_reshape=img1.reshape(num_of_image, 100*100).astype('float32')
  
  n_feats = 0.8
  pca = PCA(n_components=n_feats)
  pca.fit(img1_reshape)
  print(pca.components_[2])

  compressed = pca.transform(img1_reshape)
  new_img = pca.inverse_transform(compressed)
  return new_img

w = pca_on_data("../output/train/F0002/MID1")
for i in w:
  plt.figure()
  plt.imshow(i.reshape(100, 100))

#print(pca_on_data("../output/train/F0601/MID10"))
#plt.imshow(w)
#plt.imshow(k)

import cv2
# create a function to create,load,resize, and re-color the data
def create_data(path):
  #print("create_data:")
  #print(path)
  list_new_array=[]
  for img in os.listdir(path):
        try:
            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)
            size=100
            new_array=cv2.resize(img_array,(size,size))
            list_new_array.append(new_array)
        except Exception as e:
            pass

  return list_new_array

#combine images
def combine_images(path):
  new_img = create_data(path)
  avg_image = new_img[0]
  for i in range(len(new_img)):
    if i==0:
      pass
    else:
      a = 1.0/(i+1)
      b = 1.0 - a
      avg_image = cv2.addWeighted(new_img[i], a, avg_image, b, 0.0)
  plt.figure
  plt.imshow(avg_image)
  plt.axis("off")
  plt.title("After combining")
  return(avg_image)

print(combine_images("../output/train/F0002/MID1"))

fig = plt.figure()
value = (create_data("../output/train/F0002/MID1"))
print(value)
for i in range(10):
  fig.add_subplot(2,5,i+1)
  plt.imshow(value[i])
  plt.axis("off")
  plt.title(str(i+1))

# convert dimension of one image
def get_1D_from_input(path):
  #print("1d")

  a = combine_images(path).reshape((100*100))
  return a

#a = get_1D_from_input("../output/train/F0002/MID1")
#a = np.array(a)
#plt.figure()
#plt.imshow(a.reshape(100, 100))

def read_img(path):
  #print("read_img")
  #print(path)
  return get_1D_from_input(path)

def person_to_images_map(keyy):
  #print(keyy)
  return ("../output/train/"+keyy)

print(read_img(person_to_images_map("F0703/MID10")))

def gen(list_tuples, batch_size=300):
    ppl = list(train_person_to_images_map.keys())
    X1 = []
    X2 = []
    labels = []
    batch_tuples=[]


    for i in range(batch_size//2):
      p0 = choice(list_tuples)
      batch_tuples.append(p0)
      labels.append(1)

    for i in range(batch_size - len(batch_tuples)):
        p1 = choice(ppl)
        p2 = choice(ppl)

        if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:
                batch_tuples.append((p1, p2))
                labels.append(0)
        else:
                batch_tuples.append((p1, p2))
                labels.append(1)
    
    #print(person_to_images_map)
    for x in batch_tuples:
        X1.append(read_img(person_to_images_map(x[0])))
        X2.append(read_img(person_to_images_map(x[1])))

    X1 = np.array(X1)
    X2 = np.array(X2)
    labels = np.array(labels)

    return (X1, X2, labels)

output = gen(train, 5000)
#output will be 100 X1, 100 X2, 100 labels

"""#Building and Evaluating Models"""

#building model
from sklearn.ensemble import RandomForestClassifier
randomforest=RandomForestClassifier()

X1 = output[0].astype(np.int16)/255.0
X2 = output[1].astype(np.int16)/255.0
labels = output[2]
x_train = X2 - X1
y_train = labels

randomforest.fit(x_train, y_train)
#y_pred = model.predict(x_test)

#preparing test case
path_to_zip_file = "test.zip"
directory_to_extract_to = "../input/test"
train_images =  Path('../input/test/')
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
  zip_ref.extractall(directory_to_extract_to)

# create a function to create,load,resize, and re-color the data
def create_data_test(img):
  list_new_array=[]
  img_array=cv2.imread(os.path.join('../input/test/',img),cv2.IMREAD_GRAYSCALE)
  size=100
  new_array=cv2.resize(img_array,(size,size))
  list_new_array.append(new_array)
  return (np.array(list_new_array))
      
#convert dimension of one image
def get_1D_from_input_test(img):
  a = create_data_test(img).reshape((100*100))
  return a

def read_img_test(img,):
  return get_1D_from_input_test(img)

print(read_img_test('face00000.jpg'))

def chunker(seq, size=32):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))

from tqdm import tqdm

test_path = "../input/test/"

submission = pd.read_csv('/content/sample_submission.csv')

predictions = []

for batch in tqdm(chunker(submission.img_pair.values)):
    X1_file = [x.split("-")[0] for x in batch]
    X1 = np.array([read_img_test(x) for x in X1_file]).astype(np.int16)/255.0
    #X1 = np.array([read_img_test(test_path + x) for x in X1])
    X2_file = [x.split("-")[1] for x in batch]
    X2 = np.array([read_img_test(x) for x in X2_file]).astype(np.int16)/255.0
    #X2 = np.array([read_img_test(test_path + x) for x in X2])
    x_test = X1-X2
    
    print(X1)
    print(X2)
    print(x_test)

    pred = randomforest.predict(x_test).ravel().tolist()
    predictions += pred

submission['is_related'] = predictions

submission.to_csv("/content/drive/MyDrive/Projects file sharing/CZ4041_Project_KaeBoon/randomforest.csv", index=False)



"""# not related to cz4041"""

from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
import numpy as np
import cv2
from PIL import Image

(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

print(x_train)

print(x_train.shape)

for data in x_train:
  img = Image.fromarray(data, 'RGB')
  img.show()

print([1]*5)

import facemorpher